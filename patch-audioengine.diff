--- a/openai-transcriber-ios/AudioEngineRecorder.swift
+++ b/openai-transcriber-ios/AudioEngineRecorder.swift
@@
-import Foundation
-import AVFoundation
-import Speech
-import VoiceActivityDetector   // WebRTC VAD ラッパ
-import Accelerate              // vDSP（RMS 計算など）で使用
+import Foundation
+import AVFoundation
+import Speech
+import VoiceActivityDetector   // WebRTC VAD ラッパ
+import Accelerate              // vDSP（RMS 計算など）で使用
 
 /// ── WebRTC VAD インスタンス ─────────────────────────
 private let vad = VoiceActivityDetector(
     sampleRate: 16_000,
     aggressiveness: .quality)  // .quality / .aggressive / .veryAggressive
@@
-    private let engine = AVAudioEngine
+    /// 入力用オーディオ・エンジン
+    private let engine = AVAudioEngine()
 
 // MARK: - 初期化 ------------------------------------------------
     init() {
-        // vad.aggressiveness = 1 // This is now set in the constructor
-        engine = AVAudioEngine()
-
-        // ── AudioSession 構成を明示 ─────────────────────────
+        // ── AudioSession 構成を明示 ─────────────────────────
         let session = AVAudioSession.sharedInstance()
         try? session.setCategory(.playAndRecord,
                                  mode: .measurement,
                                  options: [.defaultToSpeaker, .allowBluetooth])
         try? session.setActive(true)
-
-        // ── Tap を設定（まだ付いていなければ）────────────────
-        let input  = engine.inputNode
-        let format = input.outputFormat(forBus: 0) // Format for init tap
-
-        // Tap in init (bufferSize 256)
-        input.installTap(onBus: 0, bufferSize: 256, format: format) {
-            [weak self] buffer, _ in
-            self?.processVAD(buffer)
-        }
-        // Tap は start() で付けるように変更（重複回避）
     }
 
@@
-            self?.processVAD(buffer)
-            let rms = buffer.rmsMagnitude()
-            Debug.log(String(format: "🎙️ in-RMS = %.5f", rms))
-            self?.process(buffer: buffer, format: format)
+            self?.processVAD(buffer)                 // VAD でスピーチ判定
+            let rms = buffer.rmsMagnitude()          // 参考ログ
+            Debug.log(String(format: "🎙️ RMS = %.5f", rms))
         }
@@     private func processVAD(_ buffer: AVAudioPCMBuffer)
-        // Float → Int16 （vDSP でスケール＆丸め）
-        // Create a mutable copy for floatPCM if buffer.floatChannelData provides non-mutable
-        var mutableCh = Array(UnsafeBufferPointer(start: ch, count: n))
-        let floatPCM = channelData.map { $0 * Float(Int16.max) }
+        // Float → Int16 （vDSP でスケール＆丸め）
+        let floatPCM = (0..<n).map { i -> Float in
+            ch[i] * Float(Int16.max)
+        }
@@
-            try? audioFile?.write(from: buffer) // Write the original buffer
+            try? audioFile?.write(from: buffer) // 音声を書き込み
             silenceStart = nil
             isSpeaking   = true
@@
-        if bytes < minSegmentBytes {   // avgRMS 判定は不要になったので簡略
+        if bytes < minSegmentBytes {            // 極短 or 無音ファイルは破棄
             try? FileManager.default.removeItem(at: url)
             resetState()
             return
         }
@@
-    /// 変数を初期化して次の録音に備える
+    /// 変数を初期化して次の録音に備える
     private func resetState() {
         audioFile    = nil
         fileURL      = nil
         silenceStart = nil
         startDate    = Date()
     }
-
-    // MARK: - 後片付け -----------------------------------------
-    deinit { /* Fvad はクラスなので明示解放不要 */ }
+
+    // MARK: - 後片付け -----------------------------------------
+    deinit { /* Fvad はクラスなので明示解放不要 */ }
 }
