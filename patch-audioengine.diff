--- a/openai-transcriber-ios/AudioEngineRecorder.swift
+++ b/openai-transcriber-ios/AudioEngineRecorder.swift
@@
-import Foundation
-import AVFoundation
-import Speech
-import VoiceActivityDetector   // WebRTC VAD ãƒ©ãƒƒãƒ‘
-import Accelerate              // vDSPï¼ˆRMS è¨ˆç®—ãªã©ï¼‰ã§ä½¿ç”¨
+import Foundation
+import AVFoundation
+import Speech
+import VoiceActivityDetector   // WebRTC VAD ãƒ©ãƒƒãƒ‘
+import Accelerate              // vDSPï¼ˆRMS è¨ˆç®—ãªã©ï¼‰ã§ä½¿ç”¨
 
 /// â”€â”€ WebRTC VAD ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 private let vad = VoiceActivityDetector(
     sampleRate: 16_000,
     aggressiveness: .quality)  // .quality / .aggressive / .veryAggressive
@@
-    private let engine = AVAudioEngine
+    /// å…¥åŠ›ç”¨ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ»ã‚¨ãƒ³ã‚¸ãƒ³
+    private let engine = AVAudioEngine()
 
 // MARK: - åˆæœŸåŒ– ------------------------------------------------
     init() {
-        // vad.aggressiveness = 1 // This is now set in the constructor
-        engine = AVAudioEngine()
-
-        // â”€â”€ AudioSession æ§‹æˆã‚’æ˜ç¤º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+        // â”€â”€ AudioSession æ§‹æˆã‚’æ˜ç¤º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         let session = AVAudioSession.sharedInstance()
         try? session.setCategory(.playAndRecord,
                                  mode: .measurement,
                                  options: [.defaultToSpeaker, .allowBluetooth])
         try? session.setActive(true)
-
-        // â”€â”€ Tap ã‚’è¨­å®šï¼ˆã¾ã ä»˜ã„ã¦ã„ãªã‘ã‚Œã°ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-        let input  = engine.inputNode
-        let format = input.outputFormat(forBus: 0) // Format for init tap
-
-        // Tap in init (bufferSize 256)
-        input.installTap(onBus: 0, bufferSize: 256, format: format) {
-            [weak self] buffer, _ in
-            self?.processVAD(buffer)
-        }
-        // Tap ã¯ start() ã§ä»˜ã‘ã‚‹ã‚ˆã†ã«å¤‰æ›´ï¼ˆé‡è¤‡å›é¿ï¼‰
     }
 
@@
-            self?.processVAD(buffer)
-            let rms = buffer.rmsMagnitude()
-            Debug.log(String(format: "ğŸ™ï¸ in-RMS = %.5f", rms))
-            self?.process(buffer: buffer, format: format)
+            self?.processVAD(buffer)                 // VAD ã§ã‚¹ãƒ”ãƒ¼ãƒåˆ¤å®š
+            let rms = buffer.rmsMagnitude()          // å‚è€ƒãƒ­ã‚°
+            Debug.log(String(format: "ğŸ™ï¸ RMS = %.5f", rms))
         }
@@     private func processVAD(_ buffer: AVAudioPCMBuffer)
-        // Float â†’ Int16 ï¼ˆvDSP ã§ã‚¹ã‚±ãƒ¼ãƒ«ï¼†ä¸¸ã‚ï¼‰
-        // Create a mutable copy for floatPCM if buffer.floatChannelData provides non-mutable
-        var mutableCh = Array(UnsafeBufferPointer(start: ch, count: n))
-        let floatPCM = channelData.map { $0 * Float(Int16.max) }
+        // Float â†’ Int16 ï¼ˆvDSP ã§ã‚¹ã‚±ãƒ¼ãƒ«ï¼†ä¸¸ã‚ï¼‰
+        let floatPCM = (0..<n).map { i -> Float in
+            ch[i] * Float(Int16.max)
+        }
@@
-            try? audioFile?.write(from: buffer) // Write the original buffer
+            try? audioFile?.write(from: buffer) // éŸ³å£°ã‚’æ›¸ãè¾¼ã¿
             silenceStart = nil
             isSpeaking   = true
@@
-        if bytes < minSegmentBytes {   // avgRMS åˆ¤å®šã¯ä¸è¦ã«ãªã£ãŸã®ã§ç°¡ç•¥
+        if bytes < minSegmentBytes {            // æ¥µçŸ­ or ç„¡éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç ´æ£„
             try? FileManager.default.removeItem(at: url)
             resetState()
             return
         }
@@
-    /// å¤‰æ•°ã‚’åˆæœŸåŒ–ã—ã¦æ¬¡ã®éŒ²éŸ³ã«å‚™ãˆã‚‹
+    /// å¤‰æ•°ã‚’åˆæœŸåŒ–ã—ã¦æ¬¡ã®éŒ²éŸ³ã«å‚™ãˆã‚‹
     private func resetState() {
         audioFile    = nil
         fileURL      = nil
         silenceStart = nil
         startDate    = Date()
     }
-
-    // MARK: - å¾Œç‰‡ä»˜ã‘ -----------------------------------------
-    deinit { /* Fvad ã¯ã‚¯ãƒ©ã‚¹ãªã®ã§æ˜ç¤ºè§£æ”¾ä¸è¦ */ }
+
+    // MARK: - å¾Œç‰‡ä»˜ã‘ -----------------------------------------
+    deinit { /* Fvad ã¯ã‚¯ãƒ©ã‚¹ãªã®ã§æ˜ç¤ºè§£æ”¾ä¸è¦ */ }
 }
