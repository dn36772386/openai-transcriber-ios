//
//  AudioFileProcessor.swift
//  openai-transcriber-ios
//
//  Created by apple on 2025/05/24.
//

import Foundation
import AVFoundation
import Accelerate

/// éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ç„¡éŸ³ã§åˆ†å‰²ã™ã‚‹ãƒ—ãƒ­ã‚»ãƒƒã‚µ
@available(iOS 16.0, *)
final class AudioFileProcessor: ObservableObject {
    
    // MARK: - Types
    struct ProcessingResult {
        let segments: [(url: URL, startTime: TimeInterval, duration: TimeInterval)]
        let totalDuration: TimeInterval
    }
    
    enum ProcessingError: Error {
        case fileNotFound
        case unsupportedFormat
        case conversionFailed
        case processingFailed(String)
    }
    
    // MARK: - Properties
    @Published var isProcessing = false
    @Published var progress: Double = 0.0
    
    // UserDefaultsã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã‚€ã‚ˆã†ã«å¤‰æ›´
    private var silenceThreshold: Float {
        let value = UserDefaults.standard.float(forKey: "silenceThreshold")
        return value > 0 ? value : 0.01
    }
    
    private var silenceWindow: TimeInterval {
        let value = UserDefaults.standard.double(forKey: "silenceWindow")
        return value > 0 ? value : 0.5
    }
    
    private var minSegmentDuration: TimeInterval {
        let value = UserDefaults.standard.double(forKey: "minSegmentDuration")
        return value > 0 ? value : 0.5
    }
    
    private let maxSegmentDuration: TimeInterval = 240.0  // æœ€å¤§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·ï¼ˆ4åˆ†ï¼‰
    private let maxSegmentSize: Int64 = 24 * 1024 * 1024  // æœ€å¤§24MBï¼ˆAPIã¯25MBã¾ã§ï¼‰
    private let outputFormat: AVAudioFormat
    
    // MARK: - Initialization
    init() {
        // Whisperç”¨ã®å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆ16kHz, 16bit, monoï¼‰
        self.outputFormat = AVAudioFormat(
            commonFormat: .pcmFormatInt16,
            sampleRate: 16_000,
            channels: 1,
            interleaved: true
        )!
    }
    
    // MARK: - Public Methods
    
    /// éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦ç„¡éŸ³ã§åˆ†å‰²
    func processFile(at url: URL) async throws -> ProcessingResult {
        await MainActor.run { 
            self.isProcessing = true 
            self.progress = 0.0
        }
        
        defer {
            Task { @MainActor in
                self.isProcessing = false
            }
        }
        
        Debug.log("ğŸ“Š AudioFileProcessor: Processing \(url.lastPathComponent)")
        Debug.log("ğŸ“Š File exists: \(FileManager.default.fileExists(atPath: url.path))")
        
        // è¨­å®šå€¤ã‚’ãƒ­ã‚°å‡ºåŠ›
        print("ğŸ“Š Processing with settings:")
        print("   - Silence threshold: \(silenceThreshold)")
        print("   - Silence window: \(silenceWindow)s")
        print("   - Min segment duration: \(minSegmentDuration)s")
        
        // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚³ãƒ¼ãƒ—ãƒ‰ãƒªã‚½ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹
        // ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ/tmp/å†…ï¼‰ã®å ´åˆã¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚³ãƒ¼ãƒ—ä¸è¦
        let needsSecurityScope = !url.path.contains("/tmp/")
        
        if needsSecurityScope {
            guard url.startAccessingSecurityScopedResource() else {
                Debug.log("âŒ Failed to access security scoped resource")
                throw ProcessingError.fileNotFound
            }
        }
        
        defer { 
            if needsSecurityScope { url.stopAccessingSecurityScopedResource() }
            Debug.log("ğŸ“Š Stopped accessing security scoped resource (if needed)")
        }
        
        // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼
        let validation = await AudioFormatHandler.validateFormat(url: url)
        guard validation.isValid else {
            Debug.log("âŒ Format validation failed: \(validation.error ?? "Unknown")")
            throw ProcessingError.unsupportedFormat
        }
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãï¼ˆAVAssetReader ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã‚‚ã‚ã‚‹ï¼‰
        let file: AVAudioFile
        do {
            file = try AVAudioFile(forReading: url)
            Debug.log("âœ… AVAudioFile opened successfully")
        } catch {
            Debug.log("âŒ AVAudioFile failed to open: \(error)")
            // AVAudioFileã§é–‹ã‘ãªã„å ´åˆã¯ã€å…ˆã«å¤‰æ›ãŒå¿…è¦
            throw ProcessingError.unsupportedFormat
        }
        let inputFormat = file.processingFormat
        let totalFrames = AVAudioFrameCount(file.length)
        let totalDuration = Double(totalFrames) / inputFormat.sampleRate
        
        print("ğŸ“ Processing file: \(url.lastPathComponent)")
        print("ğŸ“Š Format: \(inputFormat)")
        print("â±ï¸ Duration: \(totalDuration)s")
        
        // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
        let needsConversion = inputFormat.sampleRate != outputFormat.sampleRate ||
                            inputFormat.channelCount != outputFormat.channelCount
        
        // ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼ä½œæˆï¼ˆå¿…è¦ãªå ´åˆï¼‰
        let converter: AVAudioConverter?
        if needsConversion {
            converter = AVAudioConverter(from: inputFormat, to: outputFormat)
        } else {
            converter = nil
        }
        
        // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºï¼ˆ0.1ç§’åˆ†ï¼‰
        let bufferSize = AVAudioFrameCount(inputFormat.sampleRate * 0.1)
        
        // ç„¡éŸ³æ¤œå‡ºç”¨ã®å¤‰æ•°
        var segments: [(url: URL, startTime: TimeInterval, duration: TimeInterval)] = []
        var currentSegmentStart: TimeInterval? = nil
        var currentSegmentFrames: [AVAudioPCMBuffer] = []
        var lastSpeechTime: TimeInterval = 0
        var currentTime: TimeInterval = 0
        var currentSegmentSize: Int64 = 0
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ãªãŒã‚‰å‡¦ç†
        while file.framePosition < totalFrames {
            // ãƒãƒƒãƒ•ã‚¡ã‚’ä½œæˆ
            let remainingFrames = totalFrames - AVAudioFrameCount(file.framePosition)
            let framesToRead = min(bufferSize, remainingFrames)
            
            guard let buffer = AVAudioPCMBuffer(
                pcmFormat: inputFormat,
                frameCapacity: framesToRead
            ) else { continue }
            
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
            try file.read(into: buffer, frameCount: framesToRead)
            
            // RMSè¨ˆç®—
            let rms = calculateRMS(buffer: buffer)
            let isSpeech = rms > silenceThreshold
            
            // ç™ºè©±æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯
            if isSpeech {
                // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã‚’æ¦‚ç®—ï¼ˆ16bit, 16kHz, monoï¼‰
                let bufferSize = Int64(buffer.frameLength) * 2  // 16bit = 2bytes
                let estimatedSegmentSize = currentSegmentSize + bufferSize
                
                // ç™ºè©±é–‹å§‹
                if currentSegmentStart == nil {
                    currentSegmentStart = currentTime
                    currentSegmentFrames = []
                    print("ğŸ¤ Speech started at \(currentTime)s")
                }
                currentSegmentFrames.append(buffer)
                lastSpeechTime = currentTime
                currentSegmentSize += bufferSize
                
                // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒæœ€å¤§ã‚µã‚¤ã‚ºã¾ãŸã¯æœ€å¤§æ™‚é–“ã«é”ã—ãŸå ´åˆã€å¼·åˆ¶çš„ã«åˆ†å‰²
                let segmentDuration = currentTime - (currentSegmentStart ?? 0)
                if estimatedSegmentSize >= maxSegmentSize || segmentDuration >= maxSegmentDuration {
                    print("âš ï¸ Force splitting segment: size=\(estimatedSegmentSize/1024/1024)MB, duration=\(segmentDuration)s")
                    
                    if segmentDuration >= minSegmentDuration {
                        if let segmentURL = try await saveSegment(
                            frames: currentSegmentFrames,
                            inputFormat: inputFormat,
                            startTime: currentSegmentStart ?? currentTime,
                            duration: segmentDuration,
                            needsConversion: needsConversion,
                            converter: converter
                        ) {
                            segments.append((
                                url: segmentURL,
                                startTime: currentSegmentStart ?? currentTime,
                                duration: segmentDuration
                            ))
                            print("ğŸ’¾ Saved forced segment: \(currentSegmentStart ?? 0)s - \(currentTime)s")
                        }
                    }
                    
                    // ãƒªã‚»ãƒƒãƒˆ
                    currentSegmentStart = nil
                    currentSegmentFrames = []
                    currentSegmentSize = 0
                }
                
            } else if let segmentStart = currentSegmentStart {
                // ç„¡éŸ³æ¤œå‡º
                let silenceDuration = currentTime - lastSpeechTime
                
                if silenceDuration >= silenceWindow {
                    // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç¢ºå®š
                    let segmentDuration = lastSpeechTime - segmentStart
                    
                    if segmentDuration >= minSegmentDuration {
                        // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä¿å­˜
                        if let segmentURL = try await saveSegment(
                            frames: currentSegmentFrames,
                            inputFormat: inputFormat,
                            startTime: segmentStart,
                            duration: segmentDuration,
                            needsConversion: needsConversion,
                            converter: converter
                        ) {
                            segments.append((
                                url: segmentURL,
                                startTime: segmentStart,
                                duration: segmentDuration
                            ))
                            print("ğŸ’¾ Saved segment: \(segmentStart)s - \(lastSpeechTime)s")
                        }
                    }
                    
                    // ãƒªã‚»ãƒƒãƒˆ
                    currentSegmentStart = nil
                    currentSegmentFrames = []
                    currentSegmentSize = 0
                }
            }
            
            // æ™‚é–“ã‚’æ›´æ–°
            currentTime += Double(buffer.frameLength) / inputFormat.sampleRate
            
            // é€²æ—æ›´æ–°ï¼ˆcurrentTimeã‚’å®‰å…¨ã«ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼‰
            let capturedProgress = currentTime / totalDuration
            await MainActor.run {
                self.progress = capturedProgress
            }
        }
        
        // æœ€å¾Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†
        if let segmentStart = currentSegmentStart {
            let segmentDuration = currentTime - segmentStart
            if segmentDuration >= minSegmentDuration {
                if let segmentURL = try await saveSegment(
                    frames: currentSegmentFrames,
                    inputFormat: inputFormat,
                    startTime: segmentStart,
                    duration: segmentDuration,
                    needsConversion: needsConversion,
                    converter: converter
                ) {
                    segments.append((
                        url: segmentURL,
                        startTime: segmentStart,
                        duration: segmentDuration
                    ))
                }
            }
        }
        
        print("âœ… Processing complete: \(segments.count) segments")
        
        return ProcessingResult(
            segments: segments,
            totalDuration: totalDuration
        )
    }
    
    // MARK: - Private Methods
    
    /// ãƒãƒƒãƒ•ã‚¡ã®RMSã‚’è¨ˆç®—
    private func calculateRMS(buffer: AVAudioPCMBuffer) -> Float {
        guard let channelData = buffer.floatChannelData else { return 0 }
        
        var rms: Float = 0
        let channelCount = Int(buffer.format.channelCount)
        let frameLength = Int(buffer.frameLength)
        
        // å…¨ãƒãƒ£ãƒ³ãƒãƒ«ã®RMSã‚’å¹³å‡
        for channel in 0..<channelCount {
            var channelRMS: Float = 0
            vDSP_rmsqv(channelData[channel], 1, &channelRMS, vDSP_Length(frameLength))
            rms += channelRMS
        }
        
        return rms / Float(channelCount)
    }
    
    /// ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    private func saveSegment(
        frames: [AVAudioPCMBuffer],
        inputFormat: AVAudioFormat,
        startTime: TimeInterval,
        duration: TimeInterval,
        needsConversion: Bool,
        converter: AVAudioConverter?
    ) async throws -> URL? {
        
        guard !frames.isEmpty else { return nil }
        
        // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«URL
        let tempURL = FileManager.default.temporaryDirectory
            .appendingPathComponent("segment_\(UUID().uuidString).wav")
        
        // å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        let outputFile = try AVAudioFile(
            forWriting: tempURL,
            settings: outputFormat.settings,
            commonFormat: outputFormat.commonFormat,
            interleaved: outputFormat.isInterleaved
        )
        
        // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ãŒå¿…è¦ãªå ´åˆ
        if needsConversion, let converter = converter {
            // å„ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å¤‰æ›ã—ã¦æ›¸ãè¾¼ã¿
            for frame in frames {
                let outputFrameCapacity = AVAudioFrameCount(
                    Double(frame.frameLength) * outputFormat.sampleRate / inputFormat.sampleRate
                )
                
                guard let outputBuffer = AVAudioPCMBuffer(
                    pcmFormat: outputFormat,
                    frameCapacity: outputFrameCapacity
                ) else { continue }
                
                var error: NSError?
                let status = converter.convert(to: outputBuffer, error: &error) { _, outStatus in
                    outStatus.pointee = .haveData
                    return frame
                }
                
                if status == .error {
                    print("âš ï¸ Conversion error: \(error?.localizedDescription ?? "Unknown")")
                    continue
                }
                
                try outputFile.write(from: outputBuffer)
            }
        } else {
            // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ä¸è¦ãªå ´åˆã¯ç›´æ¥æ›¸ãè¾¼ã¿
            for frame in frames {
                try outputFile.write(from: frame)
            }
        }
        
        return tempURL
    }
    
    /// ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    func cleanupTemporaryFiles(urls: [URL]) {
        for url in urls {
            try? FileManager.default.removeItem(at: url)
        }
    }
}