import Foundation
import AVFoundation
import Speech
import VoiceActivityDetector   // WebRTC VAD ãƒ©ãƒƒãƒ‘
import Accelerate              // vDSPï¼ˆRMS è¨ˆç®—ãªã©ï¼‰ã§ä½¿ç”¨

/// â”€â”€ WebRTC VAD ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
private let vad = VoiceActivityDetector(
    sampleRate: 16_000,
    aggressiveness: .quality)  // .quality / .aggressive / .veryAggressive

protocol AudioEngineRecorderDelegate: AnyObject {
    func recorder(_ rec: AudioEngineRecorder,
                  didFinishSegment url: URL,
                  start: Date)
}

final class AudioEngineRecorder: ObservableObject {
    // MARK: Public
    /// éŒ²éŸ³çŠ¶æ…‹
    /// SwiftUI ã§ `Binding` ã‚’æ‰±ãˆã‚‹ã‚ˆã† **setter ã‚’å…¬é–‹** ã—ã¾ã™
    @Published var isRecording = false
    weak var delegate: AudioEngineRecorderDelegate?

    // MARK: â€“â€“â€“â€“â€“ Private â€“â€“â€“â€“â€“
    private let silenceWindow   = 1.2           // ç™ºè©±çµ‚äº†åˆ¤å®š 1.2 sec
    private let minSegmentBytes = 12_288        // 12 kB æœªæº€ã¯ç ´æ£„

    /// ç›´è¿‘ãƒ•ãƒ¬ãƒ¼ãƒ ã§ VAD ãŒ voice ã‚’è¿”ã—ãŸã‹
    private var voiceFlag = false

    private var isSpeaking  = false
    private var silenceStart: Date?
    private var audioFile:  AVAudioFile?
    private var fileURL:    URL?
    private var startDate   = Date()

    /// å…¥åŠ›ç”¨ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ»ã‚¨ãƒ³ã‚¸ãƒ³
    private let engine = AVAudioEngine

// MARK: - åˆæœŸåŒ– ------------------------------------------------
    init() {
        // â”€â”€ AudioSession æ§‹æˆã‚’æ˜ç¤º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        let session = AVAudioSession.sharedInstance()
        try? session.setCategory(.playAndRecord,
                                 mode: .measurement,
                                 options: [.defaultToSpeaker, .allowBluetooth])
        try? session.setActive(true)
        // Tap ã¯ start() ã§ä»˜ã‘ã‚‹ã‚ˆã†ã«å¤‰æ›´ï¼ˆé‡è¤‡å›é¿ï¼‰
    }

    func start() throws {
        guard !isRecording else { return }

        try AVAudioSession.sharedInstance().setCategory(
            .playAndRecord,
            mode: .default,
            options: .defaultToSpeaker)
        try AVAudioSession.sharedInstance().setActive(true)

        // â”€â”€ Tap ã‚’è¨­å®šï¼ˆã¾ã ä»˜ã„ã¦ã„ãªã‘ã‚Œã°ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        let input  = engine.inputNode
        let format = input.inputFormat(forBus: 0)
        input.removeTap(onBus: 0)                      // å¿µã®ãŸã‚ã‚¯ãƒªã‚¢

        // Tap in start (bufferSize 1024), replacing RMS logic
        input.installTap(onBus: 0, bufferSize: 1024, format: format) { [weak self] buffer, _ in
            self?.processVAD(buffer)                 // VAD ã§ã‚¹ãƒ”ãƒ¼ãƒåˆ¤å®š
            let rms = buffer.rmsMagnitude()          // å‚è€ƒãƒ­ã‚°
            Debug.log(String(format: "ğŸ™ï¸ RMS = %.5f", rms))
        }

        // â”€â”€ Engine èµ·å‹• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        engine.prepare()
        try engine.start()

        startDate = Date()
        isRecording = true
    }

    func stop() {
        guard isRecording else { return }
        engine.inputNode.removeTap(onBus: 0)
        engine.stop()
        finalizeSegment()              // æ®‹ã‚Šã‚’ flush
        isRecording = false
    }

    /// WebRTC VAD ã§éŸ³å£°åŒºé–“ã‚’åˆ¤å®šã—ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’åˆ‡ã‚Šå‡ºã™
    private func processVAD(_ buffer: AVAudioPCMBuffer)
    {
        guard let ch  = buffer.floatChannelData?[0] else { return }

        let n = Int(buffer.frameLength)

        // Float â†’ Int16 ï¼ˆvDSP ã§ã‚¹ã‚±ãƒ¼ãƒ«ï¼†ä¸¸ã‚ï¼‰
        let floatPCM = (0..<n).map { i -> Float in
            ch[i] * Float(Int16.max)
        }
        var pcm = [Int16](repeating: 0, count: n)
        vDSP.convert(                     // Xcode-15 ä»¥é™ã®ä»£æ›¿ API
            elementsOf: floatPCM,
            to: &pcm,
            rounding: .towardNearestInteger)

        // VAD ã§ãƒã‚§ãƒƒã‚¯
        voiceFlag = false
        var idx = 0
        let frameSize = 160 // 10 ms at 16 kHz
        while idx + frameSize <= n {
            let voiced = pcm.withUnsafeBufferPointer {
                vad.detect(frames: $0.baseAddress!.advanced(by: idx),
                           lengthInMilliSec: 10)          // DetectionResult
            }
            if voiced == .voice {          // .voice / .silence
                voiceFlag = true        // ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã«ã‚»ãƒƒãƒˆ
                break
            }
            idx += frameSize
        }

        let now = Date()

        if voiceFlag {
            // â”€ ç™ºè©±ç¶™ç¶š â”€
            if audioFile == nil {
                openNewSegment(format: buffer.format)   // æ–°è¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–‹å§‹
            }
            try? audioFile?.write(from: buffer) // éŸ³å£°ã‚’æ›¸ãè¾¼ã¿
            silenceStart = nil
            isSpeaking   = true
        } else if isSpeaking {
            if silenceStart == nil { silenceStart = now }
            if let s0 = silenceStart,
               now.timeIntervalSince(s0) > silenceWindow {
                finalizeSegment()
                isSpeaking = false
            }
        }
    }

    private func openNewSegment(format: AVAudioFormat) {
        // 16-kHz / Mono / 16-bit Int WAV
        let format = AVAudioFormat(
            commonFormat: .pcmFormatInt16,
            sampleRate: 16_000,
            channels: 1,
            interleaved: true
        )!

        let fileURL = FileManager.default.temporaryDirectory
            .appendingPathComponent(UUID().uuidString)
            .appendingPathExtension("wav")

        audioFile = try? AVAudioFile(
            forWriting: fileURL,
            settings: format.settings,
            commonFormat: format.commonFormat,
            interleaved: format.isInterleaved
        )
        self.fileURL   = fileURL
    }

    private func finalizeSegment() {
        guard let url = fileURL else { return }

        // ===== ãƒ•ã‚¡ã‚¤ãƒ«å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ =============================
        let bytes = (try? FileManager.default.attributesOfItem(atPath: url.path)[.size]
                     as? NSNumber)?.intValue ?? 0

        if bytes < minSegmentBytes {            // æ¥µçŸ­ or ç„¡éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç ´æ£„
            try? FileManager.default.removeItem(at: url)
            resetState()
            return
        }

        // ===== ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ç¢ºå®šã•ã›ã¦ã‹ã‚‰ãƒ‡ãƒªã‚²ãƒ¼ãƒˆé€šçŸ¥ ================
        //audioFile?.close()                         // è¿½åŠ ï¼šå¼·åˆ¶ãƒ•ãƒ©ãƒƒã‚·ãƒ¥

        audioFile    = nil
        fileURL      = nil
        silenceStart = nil
        delegate?.recorder(self, didFinishSegment: url, start: startDate)
        startDate    = Date()
    }

    /// å¤‰æ•°ã‚’åˆæœŸåŒ–ã—ã¦æ¬¡ã®éŒ²éŸ³ã«å‚™ãˆã‚‹
    private func resetState() {
        audioFile    = nil
        fileURL      = nil
        silenceStart = nil
        startDate    = Date()
    }

    // MARK: - å¾Œç‰‡ä»˜ã‘ -----------------------------------------
    deinit { /* Fvad ã¯ã‚¯ãƒ©ã‚¹ãªã®ã§æ˜ç¤ºè§£æ”¾ä¸è¦ */ }
}
