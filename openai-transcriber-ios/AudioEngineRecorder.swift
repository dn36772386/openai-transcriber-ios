import Foundation
import AVFoundation
// import VoiceActivityDetector   // â† å‰Šé™¤
import Accelerate

// private let vad = ...          // â† å‰Šé™¤

protocol AudioEngineRecorderDelegate: AnyObject {
    func recorder(_ rec: AudioEngineRecorder,
                  didFinishSegment url: URL,
                  start: Date)
}

final class AudioEngineRecorder: ObservableObject {
    // MARK: Public
    @Published var isRecording = false
    weak var delegate: AudioEngineRecorderDelegate?

    // MARK: â€“â€“â€“â€“â€“ Private â€“â€“â€“â€“â€“
    // UserDefaultsã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã‚€ã‚ˆã†ã«å¤‰æ›´
    private var silenceWindow: Double {
        let value = UserDefaults.standard.double(forKey: "silenceWindow")
        return value > 0 ? value : 0.5
    }
    
    private let minSegmentBytes = 12_288
    
    private var silenceThreshold: Float {
        let value = UserDefaults.standard.float(forKey: "silenceThreshold")
        return value > 0 ? value : 0.01
    }
    
    // æœ€å°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ™‚é–“ã‚’è¿½åŠ 
    private var minSegmentDuration: Double {
        let value = UserDefaults.standard.double(forKey: "minSegmentDuration")
        return value > 0 ? value : 0.5
    }

    // è¨­å®šå€¤ã®ãƒ­ã‚°å‡ºåŠ›ãƒ•ãƒ©ã‚°ï¼ˆstaticï¼‰
    private static var hasLoggedSettings = false

    private var isSpeaking  = false
    private var silenceStart: Date?
    private var audioFile:  AVAudioFile?
    private var fileURL:    URL?
    private var startDate   = Date()
    private let engine = AVAudioEngine() // â—€ï¸â—€ï¸ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–

    // â—€ï¸â—€ï¸ è¿½åŠ : ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ç”¨ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ â–¼â–¼
    private var inputFormat: AVAudioFormat?
    private var outputFormat: AVAudioFormat?
    private var audioConverter: AVAudioConverter?
    // --- â–¼â–¼â–¼ ã‚¹ãƒ†ãƒƒãƒ—1ã§è¿½åŠ  â–¼â–¼â–¼ ---
    private var isCancelled = false // ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ•ãƒ©ã‚°
    // --- â–²â–²â–² ã‚¹ãƒ†ãƒƒãƒ—1ã§è¿½åŠ  â–²â–²â–² ---
    private var isManualMode = false // æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ãƒ•ãƒ©ã‚°

    // MARK: - åˆæœŸåŒ– ------------------------------------------------
    init() {
        let session = AVAudioSession.sharedInstance()
        try? session.setCategory(.playAndRecord,
                                 mode: .measurement,
                                 options: [.defaultToSpeaker, .allowBluetooth])
        try? session.setActive(true)

        // â—€ï¸â—€ï¸ è¿½åŠ : å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®šç¾© â–¼â–¼
        self.outputFormat = AVAudioFormat(
            commonFormat: .pcmFormatInt16, // 16-bit Int
            sampleRate: 16_000,           // 16 kHz
            channels: 1,                  // Mono
            interleaved: true
        )!
    }

    // --- â–¼â–¼â–¼ å¤‰æ›´ â–¼â–¼â–¼ ---
    // start ãƒ¡ã‚½ãƒƒãƒ‰ã®ä¿®æ­£ç‰ˆï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰éŒ²éŸ³å¯¾å¿œï¼‰
    func start(isManual: Bool) throws {
        guard !isRecording else { return }
        self.isManualMode = isManual
        isCancelled = false

        // ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰éŒ²éŸ³å¯¾å¿œã®AudioSessionè¨­å®š
        let session = AVAudioSession.sharedInstance()
        try session.setCategory(
            .playAndRecord,
            mode: .default,
            options: [.defaultToSpeaker, .allowBluetooth, .mixWithOthers])
        
        // ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã‚‚éŒ²éŸ³ã‚’ç¶™ç¶š
        try session.setActive(true, options: .notifyOthersOnDeactivation)

        let input = engine.inputNode
        let format = input.inputFormat(forBus: 0)
        input.removeTap(onBus: 0)

        // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨­å®š
        self.inputFormat = format
        if let inputFmt = inputFormat, let outputFmt = outputFormat {
            if inputFmt.sampleRate != outputFmt.sampleRate || 
            inputFmt.commonFormat != outputFmt.commonFormat {
                self.audioConverter = AVAudioConverter(from: inputFmt, to: outputFmt)
            } else {
                self.audioConverter = nil
            }
        }

        // ã‚¿ãƒƒãƒ—ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
        input.installTap(onBus: 0, bufferSize: 1024, format: format) { [weak self] buffer, _ in
            if self?.isManualMode == true {
                self?.processManualAudio(buffer)
            } else {
                self?.processAudio(buffer)
            }
        }

        engine.prepare()
        try engine.start()

        startDate = Date()
        isRecording = true
        
        print("ğŸ™ï¸ Recording started in \(isManual ? "manual" : "auto") mode")
        print("ğŸ™ï¸ Input format: \(format)")
        print("ğŸ™ï¸ Output format: \(String(describing: outputFormat))")
    }

    // --- â–¼â–¼â–¼ å¤‰æ›´ â–¼â–¼â–¼ ---
    // stop() ã¯ã€Œå®Œäº†ã€ã¨ã—ã¦æ‰±ã„ã¾ã™
    func stop() {
        guard isRecording else { return }
        isCancelled = false // æ­£å¸¸åœæ­¢ï¼ˆå®Œäº†ï¼‰ãªã®ã§ãƒ•ãƒ©ã‚°ã¯ false
        engine.inputNode.removeTap(onBus: 0)
        engine.stop()
        finalizeSegment()
        isRecording = false
    }

    // --- â–¼â–¼â–¼ è¿½åŠ  â–¼â–¼â–¼ ---
    // ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ¡ã‚½ãƒƒãƒ‰
    func cancel() {
        guard isRecording else { return }
        isCancelled = true // ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        engine.inputNode.removeTap(onBus: 0)
        engine.stop()

        // ã‚­ãƒ£ãƒ³ã‚»ãƒ«æ™‚ã¯ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if let url = fileURL {
            try? FileManager.default.removeItem(at: url)
            Debug.log("ğŸ—‘ï¸ Cancelled & Deleted:", url.lastPathComponent)
        }
        
        finalizeSegment() // çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆã®ãŸã‚ã«å‘¼ã¶
        isRecording = false
    }
    // --- â–²â–²â–² è¿½åŠ  â–²â–²â–² ---

    // --- â–¼â–¼â–¼ è¿½åŠ  â–¼â–¼â–¼ ---
    /// æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ã§éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹
    private func processManualAudio(_ buffer: AVAudioPCMBuffer) {
        guard !isCancelled else { return } // ã‚­ãƒ£ãƒ³ã‚»ãƒ«ä¸­ã¯å‡¦ç†ã—ãªã„

        // ã¾ã ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã„ã¦ã„ãªã‘ã‚Œã°é–‹ãï¼ˆä¸€åº¦ã ã‘ï¼‰
        if audioFile == nil {
            openNewSegment()
        }
        
        // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›
        let bufferToWrite: AVAudioPCMBuffer
        if let converter = audioConverter, let outputFmt = outputFormat {
            bufferToWrite = convertBuffer(buffer, using: converter, to: outputFmt)
        } else {
            bufferToWrite = buffer
        }
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        try? audioFile?.write(from: bufferToWrite)
    }
    // --- â–²â–²â–² è¿½åŠ  â–²â–²â–² ---

    /// RMSå€¤ã§éŸ³å£°åŒºé–“ã‚’åˆ¤å®šã—ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’åˆ‡ã‚Šå‡ºã™
    private func processAudio(_ buffer: AVAudioPCMBuffer) {
        // --- â–¼â–¼â–¼ è¿½åŠ  â–¼â–¼â–¼ ---
        guard !isCancelled else { return } // ã‚­ãƒ£ãƒ³ã‚»ãƒ«ä¸­ã¯å‡¦ç†ã—ãªã„
        // --- â–²â–²â–² è¿½åŠ  â–²â–²â–² ---

        let rms = buffer.rmsMagnitude() // RMSå€¤ã‚’å–å¾—
        let now = Date()

        // åˆå›ã®ã¿è¨­å®šå€¤ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆstaticå¤‰æ•°ã‚’å¤–éƒ¨ã«ç§»å‹•ï¼‰
        if !AudioEngineRecorder.hasLoggedSettings {
            Debug.log("ğŸ›ï¸ Audio Settings - Threshold: \(silenceThreshold), Window: \(silenceWindow)s, MinDuration: \(minSegmentDuration)s")
            AudioEngineRecorder.hasLoggedSettings = true
        }

        // Debug.log(String(format: "ğŸ™ï¸ RMS = %.5f (threshold: %.5f)", rms, silenceThreshold)) // é »ç¹ãªãƒ­ã‚°ã‚’å‰Šé™¤

        // é–¾å€¤ã‚’è¶…ãˆãŸã‚‰ã€Œç™ºè©±ä¸­ã€ã¨ã¿ãªã™
        let isVoice = rms > silenceThreshold

        if isVoice {
            // â”€ ç™ºè©±ç¶™ç¶š â”€
            if audioFile == nil {
                openNewSegment() // æ–°è¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–‹å§‹ï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¼•æ•°ã‚’å‰Šé™¤ï¼‰
            }
            
            // â—€ï¸â—€ï¸ è¿½åŠ : ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ã‚’è¡Œã† â–¼â–¼
            let bufferToWrite: AVAudioPCMBuffer
            if let converter = audioConverter, let outputFmt = outputFormat {
                // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ãŒå¿…è¦ãªå ´åˆ
                bufferToWrite = convertBuffer(buffer, using: converter, to: outputFmt)
            } else {
                // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ãŒä¸è¦ãªå ´åˆ
                bufferToWrite = buffer
            }
            try? audioFile?.write(from: bufferToWrite) // å¤‰æ›å¾Œã®éŸ³å£°ã‚’æ›¸ãè¾¼ã¿
            // â—€ï¸â—€ï¸ è¿½åŠ  â–²â–²
            
            silenceStart = nil
            isSpeaking   = true
        } else if isSpeaking {
            // â”€ ç„¡éŸ³é–‹å§‹ â”€
            if silenceStart == nil { silenceStart = now }
            // ç„¡éŸ³ãŒä¸€å®šæ™‚é–“ç¶šã„ãŸã‚‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç¢ºå®š
            if let s0 = silenceStart, now.timeIntervalSince(s0) > silenceWindow {
                // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯
                let segmentDuration = now.timeIntervalSince(startDate)
                if segmentDuration >= minSegmentDuration {
                    finalizeSegment()
                } else {
                    Debug.log("â© Segment too short (\(String(format: "%.2f", segmentDuration))s < \(minSegmentDuration)s), discarding")
                    resetState()
                }
                isSpeaking = false
            }
        }
    }

    // openNewSegment, finalizeSegment, resetState ã¯ VAD ç‰ˆã¨åŒæ§˜
    // openNewSegment ãƒ¡ã‚½ãƒƒãƒ‰ã®ä¿®æ­£ç‰ˆ
    private func openNewSegment() {
        guard !isCancelled else { return }
        guard let outputFmt = outputFormat else { return }

        let fileURL = FileManager.default.temporaryDirectory
            .appendingPathComponent(UUID().uuidString)
            .appendingPathExtension("wav")

        do {
            // WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦æ˜ç¤ºçš„ã«ä½œæˆ
            audioFile = try AVAudioFile(
                forWriting: fileURL,
                settings: outputFmt.settings,
                commonFormat: outputFmt.commonFormat,
                interleaved: outputFmt.isInterleaved
            )
            
            self.fileURL = fileURL
            self.startDate = Date()
            
            print("ğŸ“ Created new audio file: \(fileURL.lastPathComponent)")
            print("ğŸ“ Format: \(outputFmt)")
            
        } catch {
            print("âŒ Failed to create audio file: \(error)")
        }
    }

    // finalizeSegment ãƒ¡ã‚½ãƒƒãƒ‰ã®ä¿®æ­£ç‰ˆ
    private func finalizeSegment() {
        guard let url = fileURL else { resetState(); return }

        if isCancelled {
            try? FileManager.default.removeItem(at: url)
            Debug.log("ğŸ—‘ï¸ Finalize skipped/deleted due to cancel:", url.path)
            resetState()
            return
        }

        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‰ã˜ã‚‹
        audioFile = nil
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª
        let bytes = (try? FileManager.default.attributesOfItem(atPath: url.path)[.size]
                    as? NSNumber)?.intValue ?? 0
        
        // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æ™‚é–“é•·ã‚’è¨ˆç®—
        let segmentDuration = Date().timeIntervalSince(startDate)
        
        print("ğŸ“Š Segment finalized: \(url.lastPathComponent), size: \(bytes) bytes, duration: \(String(format: "%.2f", segmentDuration))s")

        // ãƒã‚¤ãƒˆæ•°ã¨æ™‚é–“é•·ã®ä¸¡æ–¹ã§ãƒã‚§ãƒƒã‚¯
        if bytes < minSegmentBytes || segmentDuration < minSegmentDuration {
            try? FileManager.default.removeItem(at: url)
            print("ğŸ—‘ï¸ Segment too small/short, deleted: \(url.lastPathComponent)")
            resetState()
            return
        }

        // AVAudioFileã‚’ä½¿ç”¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´åˆæ€§ã‚’ç¢ºèª
        do {
            let testFile = try AVAudioFile(forReading: url)
            print("âœ… Audio file valid: duration=\(Double(testFile.length) / testFile.fileFormat.sampleRate)s")
        } catch {
            print("âŒ Audio file validation failed: \(error)")
            try? FileManager.default.removeItem(at: url)
            resetState()
            return
        }

        let segmentURL = url
        let segmentStartDate = startDate
        
        // çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        fileURL = nil
        silenceStart = nil
        isSpeaking = false

        // ãƒ‡ãƒªã‚²ãƒ¼ãƒˆã«é€šçŸ¥
        delegate?.recorder(self, didFinishSegment: segmentURL, start: segmentStartDate)
        startDate = Date()
    }

    private func resetState() {
        audioFile    = nil
        fileURL      = nil
        silenceStart = nil
        startDate    = Date()
        // --- â–¼â–¼â–¼ è¿½åŠ  â–¼â–¼â–¼ ---
        isCancelled  = false // çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆæ™‚ã«ãƒ•ãƒ©ã‚°ã‚‚ãƒªã‚»ãƒƒãƒˆ
        isSpeaking   = false
        isManualMode = false // ãƒ¢ãƒ¼ãƒ‰ã‚‚ãƒªã‚»ãƒƒãƒˆ
    }

    // â—€ï¸â—€ï¸ è¿½åŠ : ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ãƒ¡ã‚½ãƒƒãƒ‰ â–¼â–¼
    private func convertBuffer(_ inputBuffer: AVAudioPCMBuffer, using converter: AVAudioConverter, to outputFormat: AVAudioFormat) -> AVAudioPCMBuffer {
        let outputFrameCapacity = AVAudioFrameCount(Double(inputBuffer.frameLength) * outputFormat.sampleRate / inputBuffer.format.sampleRate)
        guard let outputBuffer = AVAudioPCMBuffer(pcmFormat: outputFormat, frameCapacity: outputFrameCapacity) else {
            return inputBuffer // å¤‰æ›å¤±æ•—æ™‚ã¯å…ƒã®ãƒãƒƒãƒ•ã‚¡ã‚’è¿”ã™
        }
        
        var error: NSError?
        let status = converter.convert(to: outputBuffer, error: &error) { _, outStatus in
            outStatus.pointee = .haveData
            return inputBuffer
        }
        
        if status == .error {
            Debug.log("âš ï¸ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ã‚¨ãƒ©ãƒ¼: \(error?.localizedDescription ?? "Unknown")")
            return inputBuffer // å¤‰æ›å¤±æ•—æ™‚ã¯å…ƒã®ãƒãƒƒãƒ•ã‚¡ã‚’è¿”ã™
        }
        
        return outputBuffer
    }
    // â—€ï¸â—€ï¸ è¿½åŠ  â–²â–²

    deinit { /* ä½•ã‚‚ä¸è¦ */ }
}
