import Foundation
import AVFoundation
// import VoiceActivityDetector   // ‚Üê ÂâäÈô§
import Accelerate

// private let vad = ...          // ‚Üê ÂâäÈô§

protocol AudioEngineRecorderDelegate: AnyObject {
    func recorder(_ rec: AudioEngineRecorder,
                  didFinishSegment url: URL,
                  start: Date)
    func recorder(_ rec: AudioEngineRecorder,
                  didCaptureAudioBuffer buffer: Data)  // WebSocketÁî®„Å´ËøΩÂä†
}

final class AudioEngineRecorder: ObservableObject {
    // MARK: Public
    @Published var isRecording = false
    weak var delegate: AudioEngineRecorderDelegate?

    // MARK: ‚Äì‚Äì‚Äì‚Äì‚Äì Private ‚Äì‚Äì‚Äì‚Äì‚Äì
    // UserDefaults„Åã„ÇâË®≠ÂÆö„ÇíË™≠„ÅøËæº„ÇÄ„Çà„ÅÜ„Å´Â§âÊõ¥
    private var silenceWindow: Double {
        let value = UserDefaults.standard.double(forKey: "silenceWindow")
        return value > 0 ? value : 0.5
    }
    
    private let minSegmentBytes = 12_288
    
    private var silenceThreshold: Float {
        let value = UserDefaults.standard.float(forKey: "silenceThreshold")
        return value > 0 ? value : 0.01
    }
    
    // ÊúÄÂ∞è„Çª„Ç∞„É°„É≥„ÉàÊôÇÈñì„ÇíËøΩÂä†
    private var minSegmentDuration: Double {
        let value = UserDefaults.standard.double(forKey: "minSegmentDuration")
        return value > 0 ? value : 0.5
    }

    // Ë®≠ÂÆöÂÄ§„ÅÆ„É≠„Ç∞Âá∫Âäõ„Éï„É©„Ç∞ÔºàstaticÔºâ
    private static var hasLoggedSettings = false

    private var isStreamingMode = false  // WebSocket„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞„É¢„Éº„Éâ

    private var isSpeaking  = false
    private var silenceStart: Date?
    private var audioFile:  AVAudioFile?
    private var fileURL:    URL?
    private var startDate   = Date()
    private let engine = AVAudioEngine() // ‚óÄÔ∏é‚óÄÔ∏é „Ç§„É≥„Çπ„Çø„É≥„ÇπÂåñ
    private var pendingBuffers: [AVAudioPCMBuffer] = []  // „Çª„Ç∞„É°„É≥„ÉàÂàá„ÇäÊõø„Åà‰∏≠„ÅÆ„Éê„ÉÉ„Éï„Ç°‰øùÊåÅ
    private var isFinalizingSegment = false              // „Çª„Ç∞„É°„É≥„ÉàÂá¶ÁêÜ‰∏≠„Éï„É©„Ç∞

    // ‚óÄÔ∏é‚óÄÔ∏é ËøΩÂä†: „Éï„Ç©„Éº„Éû„ÉÉ„ÉàÂ§âÊèõÁî®„Éó„É≠„Éë„ÉÜ„Ç£ ‚ñº‚ñº
    private var inputFormat: AVAudioFormat?
    private var outputFormat: AVAudioFormat?
    private var audioConverter: AVAudioConverter?
    // --- ‚ñº‚ñº‚ñº „Çπ„ÉÜ„ÉÉ„Éó1„ÅßËøΩÂä† ‚ñº‚ñº‚ñº ---
    private var isCancelled = false // „Ç≠„É£„É≥„Çª„É´„Éï„É©„Ç∞
    // --- ‚ñ≤‚ñ≤‚ñ≤ „Çπ„ÉÜ„ÉÉ„Éó1„ÅßËøΩÂä† ‚ñ≤‚ñ≤‚ñ≤ ---
    private var isManualMode = false // ÊâãÂãï„É¢„Éº„Éâ„Éï„É©„Ç∞

    // MARK: - ÂàùÊúüÂåñ ------------------------------------------------
    init() {
        let session = AVAudioSession.sharedInstance()
        try? session.setCategory(.playAndRecord,
                                 mode: .measurement,
                                 options: [.defaultToSpeaker, .allowBluetooth])
        try? session.setActive(true)

        // ‚óÄÔ∏é‚óÄÔ∏é ËøΩÂä†: Âá∫Âäõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„ÇíÂÆöÁæ© ‚ñº‚ñº
        self.outputFormat = AVAudioFormat(
            commonFormat: .pcmFormatInt16, // 16-bit Int
            sampleRate: 16_000,           // 16 kHz
            channels: 1,                  // Mono
            interleaved: true
        )!
    }

    // --- ‚ñº‚ñº‚ñº Â§âÊõ¥ ‚ñº‚ñº‚ñº ---
    // start „É°„ÇΩ„ÉÉ„Éâ„ÅÆ‰øÆÊ≠£ÁâàÔºà„Éê„ÉÉ„ÇØ„Ç∞„É©„Ç¶„É≥„ÉâÈå≤Èü≥ÂØæÂøúÔºâ
    func start(isManual: Bool, isStreaming: Bool = false) throws {
        guard !isRecording else { return }
        self.isManualMode = isManual
        self.isStreamingMode = isStreaming
        isCancelled = false

        // „Éê„ÉÉ„ÇØ„Ç∞„É©„Ç¶„É≥„ÉâÈå≤Èü≥ÂØæÂøú„ÅÆAudioSessionË®≠ÂÆö
        let session = AVAudioSession.sharedInstance()
        try session.setCategory(
            .playAndRecord,
            mode: .default,
            options: [.defaultToSpeaker, .allowBluetooth, .mixWithOthers])
        
        // „Éê„ÉÉ„ÇØ„Ç∞„É©„Ç¶„É≥„Éâ„Åß„ÇÇÈå≤Èü≥„ÇíÁ∂ôÁ∂ö
        try session.setActive(true, options: .notifyOthersOnDeactivation)

        let input = engine.inputNode
        let format = input.inputFormat(forBus: 0)
        input.removeTap(onBus: 0)

        // „Éï„Ç©„Éº„Éû„ÉÉ„ÉàË®≠ÂÆö
        self.inputFormat = format
        if let inputFmt = inputFormat, let outputFmt = outputFormat {
            if inputFmt.sampleRate != outputFmt.sampleRate || 
            inputFmt.commonFormat != outputFmt.commonFormat {
                self.audioConverter = AVAudioConverter(from: inputFmt, to: outputFmt)
            } else {
                self.audioConverter = nil
            }
        }

        // „Çø„ÉÉ„Éó„Çí„Ç§„É≥„Çπ„Éà„Éº„É´
        input.installTap(onBus: 0, bufferSize: 1024, format: format) { [weak self] buffer, _ in
            if self?.isManualMode == true {
                self?.processManualAudio(buffer)
            } else if self?.isStreamingMode == true {
                self?.processStreamingAudio(buffer)
            } else {
                self?.processAudio(buffer)
            }
        }

        engine.prepare()
        try engine.start()

        startDate = Date()
        isRecording = true
        
        print("üéôÔ∏è Recording started in \(isManual ? "manual" : "auto") mode")
        print("üéôÔ∏è Input format: \(format)")
        print("üéôÔ∏è Output format: \(String(describing: outputFormat))")
    }

    // --- ‚ñº‚ñº‚ñº Â§âÊõ¥ ‚ñº‚ñº‚ñº ---
    // stop() „ÅØ„ÄåÂÆå‰∫Ü„Äç„Å®„Åó„Å¶Êâ±„ÅÑ„Åæ„Åô
    func stop() {
        guard isRecording else { return }
        isCancelled = false // Ê≠£Â∏∏ÂÅúÊ≠¢ÔºàÂÆå‰∫ÜÔºâ„Å™„ÅÆ„Åß„Éï„É©„Ç∞„ÅØ false
        engine.inputNode.removeTap(onBus: 0)
        engine.stop()
        finalizeSegment()
        isRecording = false
    }

    // --- ‚ñº‚ñº‚ñº ËøΩÂä† ‚ñº‚ñº‚ñº ---
    // „Ç≠„É£„É≥„Çª„É´„É°„ÇΩ„ÉÉ„Éâ
    func cancel() {
        guard isRecording else { return }
        isCancelled = true // „Ç≠„É£„É≥„Çª„É´„Éï„É©„Ç∞„ÇíÁ´ã„Å¶„Çã
        engine.inputNode.removeTap(onBus: 0)
        engine.stop()

        // „Ç≠„É£„É≥„Çª„É´ÊôÇ„ÅØÁèæÂú®„ÅÆ„Éï„Ç°„Ç§„É´„ÇíÂâäÈô§
        if let url = fileURL {
            try? FileManager.default.removeItem(at: url)
            Debug.log("üóëÔ∏è Cancelled & Deleted:", url.lastPathComponent)
        }
        
        finalizeSegment() // Áä∂ÊÖã„É™„Çª„ÉÉ„Éà„ÅÆ„Åü„ÇÅ„Å´Âëº„Å∂
        isRecording = false
    }
    // --- ‚ñ≤‚ñ≤‚ñ≤ ËøΩÂä† ‚ñ≤‚ñ≤‚ñ≤ ---

    // --- ‚ñº‚ñº‚ñº ËøΩÂä† ‚ñº‚ñº‚ñº ---
    /// ÊâãÂãï„É¢„Éº„Éâ„ÅßÈü≥Â£∞„Éá„Éº„Çø„ÇíÂá¶ÁêÜ„Åô„Çã
    private func processManualAudio(_ buffer: AVAudioPCMBuffer) {
        guard !isCancelled else { return } // „Ç≠„É£„É≥„Çª„É´‰∏≠„ÅØÂá¶ÁêÜ„Åó„Å™„ÅÑ

        // „Åæ„Å†„Éï„Ç°„Ç§„É´„ÇíÈñã„ÅÑ„Å¶„ÅÑ„Å™„Åë„Çå„Å∞Èñã„ÅèÔºà‰∏ÄÂ∫¶„Å†„ÅëÔºâ
        if audioFile == nil {
            openNewSegment()
        }
        
        // „Éï„Ç©„Éº„Éû„ÉÉ„ÉàÂ§âÊèõ
        let bufferToWrite: AVAudioPCMBuffer
        if let converter = audioConverter, let outputFmt = outputFormat {
            bufferToWrite = convertBuffer(buffer, using: converter, to: outputFmt)
        } else {
            bufferToWrite = buffer
        }
        
        // „Éï„Ç°„Ç§„É´„Å´Êõ∏„ÅçËæº„Åø
        try? audioFile?.write(from: bufferToWrite)
    }
    // --- ‚ñ≤‚ñ≤‚ñ≤ ËøΩÂä† ‚ñ≤‚ñ≤‚ñ≤ ---
    
    // --- ‚ñº‚ñº‚ñº ËøΩÂä†: „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞„É¢„Éº„ÉâÁî® ‚ñº‚ñº‚ñº ---
    private func processStreamingAudio(_ buffer: AVAudioPCMBuffer) {
        guard !isCancelled else { return }
        
        // „Éï„Ç©„Éº„Éû„ÉÉ„ÉàÂ§âÊèõ
        let bufferToSend: AVAudioPCMBuffer
        if let converter = audioConverter, let outputFmt = outputFormat {
            bufferToSend = convertBuffer(buffer, using: converter, to: outputFmt)
        } else {
            bufferToSend = buffer
        }
        
        // „Éá„Éº„Çø„ÇíDelegate„Å´ÈÄÅ‰ø°
        if let audioData = bufferToSend.toData() {
            delegate?.recorder(self, didCaptureAudioBuffer: audioData)
        }
    }
    // --- ‚ñ≤‚ñ≤‚ñ≤ ËøΩÂä† ‚ñ≤‚ñ≤‚ñ≤ ---

    /// RMSÂÄ§„ÅßÈü≥Â£∞Âå∫Èñì„ÇíÂà§ÂÆö„Åó„Çª„Ç∞„É°„É≥„Éà„ÇíÂàá„ÇäÂá∫„Åô
    private func processAudio(_ buffer: AVAudioPCMBuffer) {
        // --- ‚ñº‚ñº‚ñº ËøΩÂä† ‚ñº‚ñº‚ñº ---
        guard !isCancelled else { return } // „Ç≠„É£„É≥„Çª„É´‰∏≠„ÅØÂá¶ÁêÜ„Åó„Å™„ÅÑ
        // --- ‚ñ≤‚ñ≤‚ñ≤ ËøΩÂä† ‚ñ≤‚ñ≤‚ñ≤ ---

        // „Çª„Ç∞„É°„É≥„ÉàÂá¶ÁêÜ‰∏≠„ÅØ‰∏ÄÊôÇ‰øùÂ≠ò
        if isFinalizingSegment {
            Debug.log("üîÑ Buffering audio during segment finalization")
            pendingBuffers.append(buffer)
            return
        }

        let rms = buffer.rmsMagnitude() // RMSÂÄ§„ÇíÂèñÂæó
        let now = Date()

        // ÂàùÂõû„ÅÆ„ÅøË®≠ÂÆöÂÄ§„Çí„É≠„Ç∞Âá∫ÂäõÔºàstaticÂ§âÊï∞„ÇíÂ§ñÈÉ®„Å´ÁßªÂãïÔºâ
        if !AudioEngineRecorder.hasLoggedSettings {
            Debug.log("üéõÔ∏è Audio Settings - Threshold: \(silenceThreshold), Window: \(silenceWindow)s, MinDuration: \(minSegmentDuration)s")
            AudioEngineRecorder.hasLoggedSettings = true
        }

        // Debug.log(String(format: "üéôÔ∏è RMS = %.5f (threshold: %.5f)", rms, silenceThreshold)) // È†ªÁπÅ„Å™„É≠„Ç∞„ÇíÂâäÈô§

        // ÈñæÂÄ§„ÇíË∂Ö„Åà„Åü„Çâ„ÄåÁô∫Ë©±‰∏≠„Äç„Å®„Åø„Å™„Åô
        let isVoice = rms > silenceThreshold

        if isVoice {
            // ‚îÄ Áô∫Ë©±Á∂ôÁ∂ö ‚îÄ
            if audioFile == nil {
                openNewSegment() // Êñ∞Ë¶è„Çª„Ç∞„É°„É≥„ÉàÈñãÂßãÔºà„Éï„Ç©„Éº„Éû„ÉÉ„ÉàÂºïÊï∞„ÇíÂâäÈô§Ôºâ
            }
            
            // ‚óÄÔ∏é‚óÄÔ∏é ËøΩÂä†: „Éï„Ç©„Éº„Éû„ÉÉ„ÉàÂ§âÊèõ„ÇíË°å„ÅÜ ‚ñº‚ñº
            let bufferToWrite: AVAudioPCMBuffer
            if let converter = audioConverter, let outputFmt = outputFormat {
                // „Éï„Ç©„Éº„Éû„ÉÉ„ÉàÂ§âÊèõ„ÅåÂøÖË¶Å„Å™Â†¥Âêà
                bufferToWrite = convertBuffer(buffer, using: converter, to: outputFmt)
            } else {
                // „Éï„Ç©„Éº„Éû„ÉÉ„ÉàÂ§âÊèõ„Åå‰∏çË¶Å„Å™Â†¥Âêà
                bufferToWrite = buffer
            }
            try? audioFile?.write(from: bufferToWrite) // Â§âÊèõÂæå„ÅÆÈü≥Â£∞„ÇíÊõ∏„ÅçËæº„Åø
            // ‚óÄÔ∏é‚óÄÔ∏é ËøΩÂä† ‚ñ≤‚ñ≤
            
            silenceStart = nil
            isSpeaking   = true
        } else if isSpeaking {
            // ‚îÄ ÁÑ°Èü≥ÈñãÂßã ‚îÄ
            if silenceStart == nil { silenceStart = now }
            // ÁÑ°Èü≥„Åå‰∏ÄÂÆöÊôÇÈñìÁ∂ö„ÅÑ„Åü„Çâ„Çª„Ç∞„É°„É≥„Éà„ÇíÁ¢∫ÂÆö
            if let s0 = silenceStart, now.timeIntervalSince(s0) > silenceWindow {
                // „Çª„Ç∞„É°„É≥„Éà„ÅÆÈï∑„Åï„Çí„ÉÅ„Çß„ÉÉ„ÇØ
                let segmentDuration = now.timeIntervalSince(startDate)
                if segmentDuration >= minSegmentDuration {
                    finalizeSegment()
                } else {
                    Debug.log("‚è© Segment too short (\(String(format: "%.2f", segmentDuration))s < \(minSegmentDuration)s), discarding")
                    resetState()
                }
                isSpeaking = false
            }
        }
    }

    // openNewSegment, finalizeSegment, resetState „ÅØ VAD Áâà„Å®ÂêåÊßò
    // openNewSegment „É°„ÇΩ„ÉÉ„Éâ„ÅÆ‰øÆÊ≠£Áâà
    private func openNewSegment() {
        guard !isCancelled else { return }
        guard let outputFmt = outputFormat else { return }

        Debug.log("üìù Opening new segment (pending buffers: \(pendingBuffers.count))")
        let fileURL = FileManager.default.temporaryDirectory
            .appendingPathComponent(UUID().uuidString)
            .appendingPathExtension("wav")

        do {
            // WAV„Éï„Ç°„Ç§„É´„Å®„Åó„Å¶ÊòéÁ§∫ÁöÑ„Å´‰ΩúÊàê
            audioFile = try AVAudioFile(
                forWriting: fileURL,
                settings: outputFmt.settings,
                commonFormat: outputFmt.commonFormat,
                interleaved: outputFmt.isInterleaved
            )
            
            self.fileURL = fileURL
            self.startDate = Date()
            
            print("üìù Created new audio file: \(fileURL.lastPathComponent)")
            print("üìù Format: \(outputFmt)")
            
            // ‰øùÂ≠ò„Åó„Å¶„ÅÑ„Åü„Éê„ÉÉ„Éï„Ç°„ÇíÊõ∏„ÅçËæº„ÇÄ
            if !pendingBuffers.isEmpty {
                Debug.log("‚úçÔ∏è Writing \(pendingBuffers.count) pending buffers")
                for pendingBuffer in pendingBuffers {
                    let bufferToWrite: AVAudioPCMBuffer
                    if let converter = audioConverter, let outputFmt = outputFormat {
                        bufferToWrite = convertBuffer(pendingBuffer, using: converter, to: outputFmt)
                    } else {
                        bufferToWrite = pendingBuffer
                    }
                    try? audioFile?.write(from: bufferToWrite)
                }
                pendingBuffers.removeAll()
            }
            
            // „Éï„É©„Ç∞„Çí„É™„Çª„ÉÉ„Éà
            isFinalizingSegment = false
            
        } catch {
            print("‚ùå Failed to create audio file: \(error)")
        }
    }

    // finalizeSegment „É°„ÇΩ„ÉÉ„Éâ„ÅÆ‰øÆÊ≠£Áâà
    private func finalizeSegment() {
        guard let url = fileURL else { resetState(); return }

        // „Çª„Ç∞„É°„É≥„ÉàÂá¶ÁêÜÈñãÂßã
        isFinalizingSegment = true
        
        if isCancelled {
            try? FileManager.default.removeItem(at: url)
            Debug.log("üóëÔ∏è Finalize skipped/deleted due to cancel:", url.path)
            resetState()
            return
        }

        // „Éï„Ç°„Ç§„É´„ÇíÈñâ„Åò„Çã
        audioFile = nil
        
        // „Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫„ÇíÁ¢∫Ë™ç
        let bytes = (try? FileManager.default.attributesOfItem(atPath: url.path)[.size]
                    as? NSNumber)?.intValue ?? 0
        
        // „Çª„Ç∞„É°„É≥„Éà„ÅÆÊôÇÈñìÈï∑„ÇíË®àÁÆó
        let segmentDuration = Date().timeIntervalSince(startDate)
        
        print("üìä Segment finalized: \(url.lastPathComponent), size: \(bytes) bytes, duration: \(String(format: "%.2f", segmentDuration))s")

        // „Éê„Ç§„ÉàÊï∞„Å®ÊôÇÈñìÈï∑„ÅÆ‰∏°Êñπ„Åß„ÉÅ„Çß„ÉÉ„ÇØ
        if bytes < minSegmentBytes || segmentDuration < minSegmentDuration {
            try? FileManager.default.removeItem(at: url)
            print("üóëÔ∏è Segment too small/short, deleted: \(url.lastPathComponent)")
            resetState()
            return
        }

        // AVAudioFile„Çí‰ΩøÁî®„Åó„Å¶„Éï„Ç°„Ç§„É´„ÅÆÊï¥ÂêàÊÄß„ÇíÁ¢∫Ë™ç
        do {
            let testFile = try AVAudioFile(forReading: url)
            print("‚úÖ Audio file valid: duration=\(Double(testFile.length) / testFile.fileFormat.sampleRate)s")
        } catch {
            print("‚ùå Audio file validation failed: \(error)")
            try? FileManager.default.removeItem(at: url)
            resetState()
            return
        }

        let segmentURL = url
        let segmentStartDate = startDate
        
        // Áä∂ÊÖã„Çí„É™„Çª„ÉÉ„Éà
        fileURL = nil
        silenceStart = nil
        isSpeaking = false
        
        // Âá¶ÁêÜÂÆå‰∫ÜÂæå„ÄÅÊ¨°„ÅÆ„Çª„Ç∞„É°„É≥„Éà„ÅåÂç≥Â∫ß„Å´ÈñãÂßã„Åß„Åç„Çã„Çà„ÅÜ„Å´„Éï„É©„Ç∞„Çí„É™„Çª„ÉÉ„Éà
        isFinalizingSegment = false

        // „Éá„É™„Ç≤„Éº„Éà„Å´ÈÄöÁü•
        delegate?.recorder(self, didFinishSegment: segmentURL, start: segmentStartDate)
        startDate = Date()
    }

    private func resetState() {
        audioFile    = nil
        fileURL      = nil
        silenceStart = nil
        startDate    = Date()
        // --- ‚ñº‚ñº‚ñº ËøΩÂä† ‚ñº‚ñº‚ñº ---
        isCancelled  = false // Áä∂ÊÖã„É™„Çª„ÉÉ„ÉàÊôÇ„Å´„Éï„É©„Ç∞„ÇÇ„É™„Çª„ÉÉ„Éà
        isSpeaking   = false
        isManualMode = false // „É¢„Éº„Éâ„ÇÇ„É™„Çª„ÉÉ„Éà
        pendingBuffers.removeAll()  // ‰øùÂ≠ò„Éê„ÉÉ„Éï„Ç°„ÇÇ„ÇØ„É™„Ç¢
        isFinalizingSegment = false // „Éï„É©„Ç∞„ÇÇ„É™„Çª„ÉÉ„Éà
    }

    // ‚óÄÔ∏é‚óÄÔ∏é ËøΩÂä†: „Éï„Ç©„Éº„Éû„ÉÉ„ÉàÂ§âÊèõ„É°„ÇΩ„ÉÉ„Éâ ‚ñº‚ñº
    private func convertBuffer(_ inputBuffer: AVAudioPCMBuffer, using converter: AVAudioConverter, to outputFormat: AVAudioFormat) -> AVAudioPCMBuffer {
        let outputFrameCapacity = AVAudioFrameCount(Double(inputBuffer.frameLength) * outputFormat.sampleRate / inputBuffer.format.sampleRate)
        guard let outputBuffer = AVAudioPCMBuffer(pcmFormat: outputFormat, frameCapacity: outputFrameCapacity) else {
            return inputBuffer // Â§âÊèõÂ§±ÊïóÊôÇ„ÅØÂÖÉ„ÅÆ„Éê„ÉÉ„Éï„Ç°„ÇíËøî„Åô
        }
        
        var error: NSError?
        let status = converter.convert(to: outputBuffer, error: &error) { _, outStatus in
            outStatus.pointee = .haveData
            return inputBuffer
        }
        
        if status == .error {
            Debug.log("‚ö†Ô∏è „Éï„Ç©„Éº„Éû„ÉÉ„ÉàÂ§âÊèõ„Ç®„É©„Éº: \(error?.localizedDescription ?? "Unknown")")
            return inputBuffer // Â§âÊèõÂ§±ÊïóÊôÇ„ÅØÂÖÉ„ÅÆ„Éê„ÉÉ„Éï„Ç°„ÇíËøî„Åô
        }
        
        return outputBuffer
    }
    // ‚óÄÔ∏é‚óÄÔ∏é ËøΩÂä† ‚ñ≤‚ñ≤

    deinit { /* ‰Ωï„ÇÇ‰∏çË¶Å */ }
}

// MARK: - AVAudioPCMBuffer Extension
extension AVAudioPCMBuffer {
    func toData() -> Data? {
        let audioFormat = self.format
        let frameCount = self.frameLength
        
        guard let channelData = self.int16ChannelData else { return nil }
        
        let channelCount = Int(audioFormat.channelCount)
        let audioData = NSMutableData()
        
        for frame in 0..<Int(frameCount) {
            for channel in 0..<channelCount {
                var sample = channelData[channel][frame]  // var „Å´Â§âÊõ¥
                audioData.append(&sample, length: MemoryLayout<Int16>.size)
            }
        }
        
        return audioData as Data
    }
}
