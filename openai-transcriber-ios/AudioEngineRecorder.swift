import Foundation
import AVFoundation
import Accelerate

protocol AudioEngineRecorderDelegate: AnyObject {
    func recorder(_ rec: AudioEngineRecorder,
                  didFinishSegment url: URL,
                  start: Date)
}

final class AudioEngineRecorder: ObservableObject {
    // MARK: Public
    /// éŒ²éŸ³çŠ¶æ…‹
    /// SwiftUI ã§ `Binding` ã‚’æ‰±ãˆã‚‹ã‚ˆã† **setter ã‚’å…¬é–‹** ã—ã¾ã™
    @Published var isRecording = false
    weak var delegate: AudioEngineRecorderDelegate?

    init() {
        //engine = AVAudioEngine() // engineã®åˆæœŸåŒ–ã¯ã‚¯ãƒ©ã‚¹ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å®£è¨€ã§è¡Œã‚ã‚Œã¦ã„ã‚‹ãŸã‚ä¸è¦

        // â”€â”€ AudioSession æ§‹æˆã‚’æ˜ç¤º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        let session = AVAudioSession.sharedInstance()
        try? session.setCategory(.playAndRecord,
                                 mode: .measurement,
                                 options: [.defaultToSpeaker, .allowBluetooth])
        try? session.setActive(true)

        // Tap ã¯ start() ã§ä»˜ã‘ã‚‹ã‚ˆã†ã«å¤‰æ›´ï¼ˆé‡è¤‡å›é¿ï¼‰
    }

    func start() throws {
        guard !isRecording else { return }

        try AVAudioSession.sharedInstance().setCategory(.playAndRecord,
                                                        mode: .default,
                                                        options: .defaultToSpeaker)
        try AVAudioSession.sharedInstance().setActive(true)

        // â”€â”€ Tap ã‚’è¨­å®šï¼ˆã¾ã ä»˜ã„ã¦ã„ãªã‘ã‚Œã°ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        let input  = engine.inputNode
        let format = input.inputFormat(forBus: 0)
        input.removeTap(onBus: 0)                      // å¿µã®ãŸã‚ã‚¯ãƒªã‚¢

        input.installTap(onBus: 0, bufferSize: 1024, format: format) {
            [weak self] buffer, time in
            let rms = buffer.rmsMagnitude()
            Debug.log(String(format: "ğŸ™ï¸ in-RMS = %.5f", rms))
            self?.process(buffer: buffer, format: format)
        }

        // â”€â”€ Engine èµ·å‹• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        engine.prepare()
        try engine.start()

        startDate = Date()
        isRecording = true
    }

    func stop() {
        guard isRecording else { return }
        engine.inputNode.removeTap(onBus: 0)
        engine.stop()
        finalizeSegment()              // æ®‹ã‚Šã‚’ flush
        isRecording = false
    }

    // MARK: â€“â€“â€“â€“â€“ Private â€“â€“â€“â€“â€“
    private let engine           = AVAudioEngine()
    /// ç„¡éŸ³åˆ¤å®šã—ãã„å€¤ï¼ˆç’°å¢ƒãƒã‚¤ã‚ºãŒã‚ã‚‹ç¨‹åº¦ã‚ã£ã¦ã‚‚åˆ‡ã‚Œãªã„ã‚ˆã†ç·©å’Œï¼‰
    private let silenceThreshold = Float(0.005)   // â‰’ â€“40 dBFS
    /// ç„¡éŸ³ç¶™ç¶šæ™‚é–“ï¼ˆç™ºè©±çµ‚äº†åˆ¤å®šï¼‰
    private let silenceWindow    = 0.5            // 1200 ms
    /// Whisper ã¸é€ã‚‰ãªã„æ¥µçŸ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒã‚¤ã‚ºã®ã¿ãªã©ï¼‰ã‚µã‚¤ã‚ºä¸‹é™
    private let minSegmentBytes  = 6288         // < 12 kB ã¯ç ´æ£„
    private let minSegmentRMS    = Float(0.003)   // å¹³å‡ RMS ãŒã“ã‚Œæœªæº€ãªã‚‰ç„¡éŸ³æ‰±ã„

    /// true ãªã‚‰ç¾åœ¨ã€Œç™ºè©±åŒºé–“ã€ã«ã„ã‚‹
    private var inSpeech = false

    private var audioFile: AVAudioFile?
    private var fileURL:  URL?
    private var silenceStart: Date?
    private var startDate  = Date()

    private func installTap() {
        let fmt = engine.inputNode.outputFormat(forBus: 0)
        engine.inputNode.installTap(onBus: 0,
                                    bufferSize: 1024,
                                    format: fmt) { [weak self] buf, _ in
            self?.process(buffer: buf, format: fmt)
        }
    }

    private func process(buffer: AVAudioPCMBuffer, format: AVAudioFormat) {
        // RMS è¨ˆç®—ï¼ˆAccelerate C API ã‚’ä½¿ç”¨ï¼‰
        guard let ch = buffer.floatChannelData?[0] else { return }
        var rms: Float = 0
        vDSP_rmsqv(ch, 1, &rms, vDSP_Length(buffer.frameLength))
        let now = Date()

        // ç„¡éŸ³åˆ¤å®š
        if rms < silenceThreshold {
            if silenceStart == nil { silenceStart = now }
        } else {
            silenceStart = nil
        }

        // ---- open / write / close ------------------------------------
        if rms >= silenceThreshold {
            // â”€ ç™ºè©±ã‚’æ¤œçŸ¥ â”€
            if !inSpeech {
                inSpeech = true
                openNewSegment(format: format)   // å£°ãŒå‡ºãŸç¬é–“ã«ã ã‘é–‹ã
            }
            silenceStart = nil                  // ç„¡éŸ³ã‚¿ã‚¤ãƒã‚’ãƒªã‚»ãƒƒãƒˆ
        } else if inSpeech {
            // â”€ ç„¡éŸ³åŒºé–“ï¼ˆç™ºè©±å¾Œï¼‰ â”€
            if silenceStart == nil { silenceStart = now }
            if let s0 = silenceStart,
               now.timeIntervalSince(s0) > silenceWindow {
                finalizeSegment()               // ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ç„¡éŸ³ã§ç¢ºå®š
                inSpeech = false
            }
        }

        // éŸ³ãŒã—ã¦ã„ã‚‹é–“ã ã‘æ›¸ãè¾¼ã‚€
        // â”€â”€â”€â”€â”€ éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®é–‹å§‹ â”€â”€â”€â”€â”€
        if audioFile == nil { openNewSegment(format: format) }
        try? audioFile?.write(from: buffer)        // in-speech æ™‚ã®ã¿å‘¼ã°ã‚Œã‚‹

        // segment close
        if let s0 = silenceStart,
           now.timeIntervalSince(s0) > silenceWindow {
            finalizeSegment()                      // ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ç„¡éŸ³ã§ç¢ºå®š
        }
    }

    private func openNewSegment(format: AVAudioFormat) {
        // 16-kHz / Mono / 16-bit Int WAV
        let format = AVAudioFormat(
            commonFormat: .pcmFormatInt16,
            sampleRate: 16_000,
            channels: 1,
            interleaved: true
        )!

        let fileURL = FileManager.default.temporaryDirectory
            .appendingPathComponent(UUID().uuidString)
            .appendingPathExtension("wav")

        audioFile = try? AVAudioFile(
            forWriting: fileURL,
            settings: format.settings,
            commonFormat: format.commonFormat,
            interleaved: format.isInterleaved
        )
        self.fileURL   = fileURL
    }

    private func finalizeSegment() {
        guard let url = fileURL else { return }

        // ===== ãƒ•ã‚¡ã‚¤ãƒ«å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ =============================
        let bytes = (try? FileManager.default.attributesOfItem(atPath: url.path)[.size]
                     as? NSNumber)?.intValue ?? 0
        // å¹³å‡ RMS ã‚’è¨ˆç®—
        let asset = AVURLAsset(url: url)
        let reader = try? AVAssetReader(asset: asset)
        var avgRMS: Float = 0
        if let track = asset.tracks(withMediaType: .audio).first {
            // å‡ºåŠ›è¨­å®šï¼ˆ32-bit Float / éã‚¤ãƒ³ã‚¿ãƒªãƒ¼ãƒ–ï¼‰
            let output = AVAssetReaderTrackOutput(
                track: track,
                outputSettings: [AVFormatIDKey: kAudioFormatLinearPCM,
                                 AVLinearPCMIsFloatKey: true,
                                 AVLinearPCMBitDepthKey: 32,
                                 AVLinearPCMIsNonInterleaved: false]
            )
            if let r = reader, r.canAdd(output) {
                r.add(output)
                r.startReading()
            }
            var samples: Int64 = 0
            while let buf = output.copyNextSampleBuffer(),
                  let block = CMSampleBufferGetDataBuffer(buf) {
                let len = CMBlockBufferGetDataLength(block)
                var data = [Float](repeating: 0, count: len/4)
                CMBlockBufferCopyDataBytes(block, atOffset: 0,
                                           dataLength: len, destination: &data)
                var rms: Float = 0
                vDSP_rmsqv(data, 1, &rms, vDSP_Length(data.count))
                avgRMS += rms * Float(data.count)
                samples += Int64(data.count)
            }
            if samples > 0 { avgRMS /= Float(samples) }
        }

        if bytes < minSegmentBytes || avgRMS < minSegmentRMS {
            try? FileManager.default.removeItem(at: url)   // ç„¡åŠ¹ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç ´æ£„
            resetState()
            return
        }

        // ===== ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ç¢ºå®šã•ã›ã¦ã‹ã‚‰ãƒ‡ãƒªã‚²ãƒ¼ãƒˆé€šçŸ¥ ================
        //audioFile?.close()                         // è¿½åŠ ï¼šå¼·åˆ¶ãƒ•ãƒ©ãƒƒã‚·ãƒ¥

        audioFile    = nil
        fileURL      = nil
        silenceStart = nil
        delegate?.recorder(self, didFinishSegment: url, start: startDate)
        startDate    = Date()
    }

    /// å¤‰æ•°ã‚’åˆæœŸåŒ–ã—ã¦æ¬¡ã®éŒ²éŸ³ã«å‚™ãˆã‚‹
    private func resetState() {
        audioFile    = nil
        fileURL      = nil
        silenceStart = nil
        startDate    = Date()
    }
}
