import Foundation
import AVFoundation
// import VoiceActivityDetector   // â† å‰Šé™¤
import Accelerate

// private let vad = ...          // â† å‰Šé™¤

protocol AudioEngineRecorderDelegate: AnyObject {
    func recorder(_ rec: AudioEngineRecorder,
                  didFinishSegment url: URL,
                  start: Date)
}

final class AudioEngineRecorder: ObservableObject {
    // MARK: Public
    @Published var isRecording = false
    weak var delegate: AudioEngineRecorderDelegate?

    // MARK: â€“â€“â€“â€“â€“ Private â€“â€“â€“â€“â€“
    private let silenceWindow   = 1.2
    private let minSegmentBytes = 12_288
    private let silenceThreshold: Float = 0.01 // â—€ï¸â—€ï¸ ç„¡éŸ³ã¨åˆ¤å®šã™ã‚‹RMSå€¤ã®é–¾å€¤ï¼ˆè¦èª¿æ•´ï¼‰

    private var isSpeaking  = false
    private var silenceStart: Date?
    private var audioFile:  AVAudioFile?
    private var fileURL:    URL?
    private var startDate   = Date()
    private let engine = AVAudioEngine() // â—€ï¸â—€ï¸ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–

    // â—€ï¸â—€ï¸ è¿½åŠ : ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ç”¨ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ â–¼â–¼
    private var inputFormat: AVAudioFormat?
    private var outputFormat: AVAudioFormat?
    private var audioConverter: AVAudioConverter?
    // â—€ï¸â—€ï¸ è¿½åŠ  â–²â–²

    // MARK: - åˆæœŸåŒ– ------------------------------------------------
    init() {
        let session = AVAudioSession.sharedInstance()
        try? session.setCategory(.playAndRecord,
                                 mode: .measurement,
                                 options: [.defaultToSpeaker, .allowBluetooth])
        try? session.setActive(true)

        // â—€ï¸â—€ï¸ è¿½åŠ : å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®šç¾© â–¼â–¼
        self.outputFormat = AVAudioFormat(
            commonFormat: .pcmFormatInt16, // 16-bit Int
            sampleRate: 16_000,           // 16 kHz
            channels: 1,                  // Mono
            interleaved: true
        )!
        // â—€ï¸â—€ï¸ è¿½åŠ  â–²â–²
    }

    func start() throws {
        guard !isRecording else { return }

        try AVAudioSession.sharedInstance().setCategory(
            .playAndRecord,
            mode: .default,
            options: .defaultToSpeaker)
        try AVAudioSession.sharedInstance().setActive(true)

        let input  = engine.inputNode
        let format = input.inputFormat(forBus: 0)
        input.removeTap(onBus: 0)

        // â—€ï¸â—€ï¸ è¿½åŠ : å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä¿å­˜ã—ã€ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼ã‚’åˆæœŸåŒ– â–¼â–¼
        self.inputFormat = format
        if let inputFmt = inputFormat, let outputFmt = outputFormat {
            // å…¥åŠ›ã¨å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒç•°ãªã‚‹å ´åˆã®ã¿ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼ã‚’ä½œæˆ
            if inputFmt.sampleRate != outputFmt.sampleRate || 
               inputFmt.commonFormat != outputFmt.commonFormat {
                self.audioConverter = AVAudioConverter(from: inputFmt, to: outputFmt)
            } else {
                self.audioConverter = nil // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒåŒã˜å ´åˆã¯å¤‰æ›ä¸è¦
            }
        }
        // â—€ï¸â—€ï¸ è¿½åŠ  â–²â–²

        // Tapã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€RMSã§éŸ³å£°åŒºé–“ã‚’åˆ¤å®š
        input.installTap(onBus: 0, bufferSize: 1024, format: format) { [weak self] buffer, _ in
            self?.processAudio(buffer) // â—€ï¸â—€ï¸ å¤‰æ›´: RMSãƒ™ãƒ¼ã‚¹ã®å‡¦ç†ã‚’å‘¼ã¶
        }

        engine.prepare()
        try engine.start()

        startDate = Date()
        isRecording = true
    }

    func stop() {
        guard isRecording else { return }
        engine.inputNode.removeTap(onBus: 0)
        engine.stop()
        finalizeSegment()
        isRecording = false
    }

    /// RMSå€¤ã§éŸ³å£°åŒºé–“ã‚’åˆ¤å®šã—ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’åˆ‡ã‚Šå‡ºã™
    private func processAudio(_ buffer: AVAudioPCMBuffer) {
        let rms = buffer.rmsMagnitude() // RMSå€¤ã‚’å–å¾—
        let now = Date()

        Debug.log(String(format: "ğŸ™ï¸ RMS = %.5f", rms)) // ãƒ­ã‚°å‡ºåŠ›

        // é–¾å€¤ã‚’è¶…ãˆãŸã‚‰ã€Œç™ºè©±ä¸­ã€ã¨ã¿ãªã™
        let isVoice = rms > silenceThreshold

        if isVoice {
            // â”€ ç™ºè©±ç¶™ç¶š â”€
            if audioFile == nil {
                openNewSegment() // æ–°è¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–‹å§‹ï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¼•æ•°ã‚’å‰Šé™¤ï¼‰
            }
            
            // â—€ï¸â—€ï¸ è¿½åŠ : ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ã‚’è¡Œã† â–¼â–¼
            let bufferToWrite: AVAudioPCMBuffer
            if let converter = audioConverter, let outputFmt = outputFormat {
                // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ãŒå¿…è¦ãªå ´åˆ
                bufferToWrite = convertBuffer(buffer, using: converter, to: outputFmt)
            } else {
                // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ãŒä¸è¦ãªå ´åˆ
                bufferToWrite = buffer
            }
            try? audioFile?.write(from: bufferToWrite) // å¤‰æ›å¾Œã®éŸ³å£°ã‚’æ›¸ãè¾¼ã¿
            // â—€ï¸â—€ï¸ è¿½åŠ  â–²â–²
            
            silenceStart = nil
            isSpeaking   = true
        } else if isSpeaking {
            // â”€ ç„¡éŸ³é–‹å§‹ â”€
            if silenceStart == nil { silenceStart = now }
            // ç„¡éŸ³ãŒä¸€å®šæ™‚é–“ç¶šã„ãŸã‚‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç¢ºå®š
            if let s0 = silenceStart, now.timeIntervalSince(s0) > silenceWindow {
                finalizeSegment()
                isSpeaking = false
            }
        }
    }

    // openNewSegment, finalizeSegment, resetState ã¯ VAD ç‰ˆã¨åŒæ§˜
    private func openNewSegment() {
        guard let outputFmt = outputFormat else { return }

        let fileURL = FileManager.default.temporaryDirectory
            .appendingPathComponent(UUID().uuidString)
            .appendingPathExtension("wav")

        audioFile = try? AVAudioFile(
            forWriting: fileURL,
            settings: outputFmt.settings,
            commonFormat: outputFmt.commonFormat,
            interleaved: outputFmt.isInterleaved
        )
        self.fileURL = fileURL
    }

    private func finalizeSegment() {
        guard let url = fileURL else { return }

        let bytes = (try? FileManager.default.attributesOfItem(atPath: url.path)[.size]
                     as? NSNumber)?.intValue ?? 0

        if bytes < minSegmentBytes { // æ¥µçŸ­ or ç„¡éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç ´æ£„
            try? FileManager.default.removeItem(at: url)
            resetState()
            return
        }

        audioFile    = nil
        fileURL      = nil
        silenceStart = nil
        delegate?.recorder(self, didFinishSegment: url, start: startDate)
        startDate    = Date()
    }

    private func resetState() {
        audioFile    = nil
        fileURL      = nil
        silenceStart = nil
        startDate    = Date()
    }

    // â—€ï¸â—€ï¸ è¿½åŠ : ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ãƒ¡ã‚½ãƒƒãƒ‰ â–¼â–¼
    private func convertBuffer(_ inputBuffer: AVAudioPCMBuffer, using converter: AVAudioConverter, to outputFormat: AVAudioFormat) -> AVAudioPCMBuffer {
        let outputFrameCapacity = AVAudioFrameCount(Double(inputBuffer.frameLength) * outputFormat.sampleRate / inputBuffer.format.sampleRate)
        guard let outputBuffer = AVAudioPCMBuffer(pcmFormat: outputFormat, frameCapacity: outputFrameCapacity) else {
            return inputBuffer // å¤‰æ›å¤±æ•—æ™‚ã¯å…ƒã®ãƒãƒƒãƒ•ã‚¡ã‚’è¿”ã™
        }
        
        var error: NSError?
        let status = converter.convert(to: outputBuffer, error: &error) { _, outStatus in
            outStatus.pointee = .haveData
            return inputBuffer
        }
        
        if status == .error {
            Debug.log("âš ï¸ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ã‚¨ãƒ©ãƒ¼: \(error?.localizedDescription ?? "Unknown")")
            return inputBuffer // å¤‰æ›å¤±æ•—æ™‚ã¯å…ƒã®ãƒãƒƒãƒ•ã‚¡ã‚’è¿”ã™
        }
        
        return outputBuffer
    }
    // â—€ï¸â—€ï¸ è¿½åŠ  â–²â–²

    deinit { /* ä½•ã‚‚ä¸è¦ */ }
}
